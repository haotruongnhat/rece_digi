{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notebook_utils as nu\n",
    "import scipy.io\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_template = {\n",
    "    \"label\": \"\",\n",
    "    \"points\": [],\n",
    "    \"group_id\": None,\n",
    "    \"shape_type\": \"polygon\",\n",
    "    \"flags\": {}\n",
    "}\n",
    "\n",
    "label_file_template = {\n",
    "    \"version\": \"4.5.6\",\n",
    "    \"flags\": {},\n",
    "    \"shapes\": [],\n",
    "    \"imagePath\": \"\",\n",
    "    \"imageData\": None,\n",
    "    \"imageHeight\": 240,\n",
    "    \"imageWidth\": 320\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mat file conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_label_folder= \"TextSnake.pytorch/dataset/total_text/Groundtruth/Polygon/Train\"\n",
    "rect_label_folder= \"TextSnake.pytorch/dataset/total_text/Groundtruth/Polygon/Train\"\n",
    "\n",
    "image_folder = \"TextSnake.pytorch/dataset/total_text/Images/Train\"\n",
    "\n",
    "mat_files = nu.list_files(polygon_label_folder, \"*.mat\")\n",
    "image_files = nu.list_files(image_folder, \"*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_to_json_conversion(mat_dict, image_name, img_size):\n",
    "    label_dict = copy.deepcopy(label_file_template)\n",
    "    label_dict[\"imagePath\"] = image_name\n",
    "    label_dict[\"imageHeight\"] = img_size[0]\n",
    "    label_dict[\"imageWidth\"] = img_size[1]\n",
    "    \n",
    "    poly_dict = mat_dict[\"polygt\"]\n",
    "    for i in range(len(poly_dict)):\n",
    "        x = poly_dict[i][1][0]\n",
    "        y = poly_dict[i][3][0]\n",
    "        label = poly_dict[i][4][0]\n",
    "        \n",
    "        points = np.stack((x,y), 1).astype(np.float32).tolist()\n",
    "    \n",
    "        instance = copy.deepcopy(shape_template)\n",
    "        instance[\"label\"] = label\n",
    "        instance[\"points\"] = points\n",
    "\n",
    "        label_dict[\"shapes\"].append(instance)\n",
    "        \n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"TextSnake.pytorch/dataset/total_text/Label/Train\"\n",
    "\n",
    "output_image_dir = \"../../Images/Train\"\n",
    "\n",
    "for file in tqdm(mat_files):\n",
    "#     file = mat_files[1]\n",
    "    mat = scipy.io.loadmat(file)\n",
    "    name = file.stem.split(\"_\")[-1]\n",
    "    image_name = name + \".jpg\"\n",
    "    \n",
    "    image_file =  Path(image_folder) / image_name\n",
    "    \n",
    "    if not image_file.is_file():\n",
    "        print(\"File not found\")\n",
    "        continue\n",
    "    \n",
    "    image_size = cv2.imread(str(image_file)).shape[:2]\n",
    "    \n",
    "    try:\n",
    "        json = mat_to_json_conversion(mat, str(Path(output_image_dir) / image_name), image_size)\n",
    "    except:\n",
    "        print(\"Error conversion\")\n",
    "    \n",
    "    nu.write_json(Path(output_dir) / (name + \".json\"), json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.zip(\"TextSnake.pytorch/dataset/total_text/Label/\", \"totaltext_label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Txt conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_json_conversion(txt_list, image_name, img_size):\n",
    "    label_dict = copy.deepcopy(label_file_template)\n",
    "    label_dict[\"imagePath\"] = image_name\n",
    "    label_dict[\"imageHeight\"] = img_size[0]\n",
    "    label_dict[\"imageWidth\"] = img_size[1]\n",
    "    \n",
    "    for i in range(len(txt_list)):\n",
    "        l = txt_list[i].strip().split(',')\n",
    "#         print(l)\n",
    "        label = \",\".join(l[8:])\n",
    "        points = np.array(l[:8]).astype(np.float32).reshape(4, 2).tolist()\n",
    "        \n",
    "        instance = copy.deepcopy(shape_template)\n",
    "        instance[\"label\"] = label\n",
    "        instance[\"points\"] = points\n",
    "\n",
    "        label_dict[\"shapes\"].append(instance)\n",
    "        \n",
    "    return label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1105/1105 [02:11<00:00,  8.41it/s]\n"
     ]
    }
   ],
   "source": [
    "txt_label_folder= \"datasets/Coop_export/full_image\"\n",
    "image_folder = \"datasets/ReceiptCOOPData_v0.1_image\"\n",
    "\n",
    "txt_files = nu.list_files(txt_label_folder, \"*.txt\")\n",
    "\n",
    "output_image_dir = \"../ReceiptCOOPData_v0.1_image\"\n",
    "output_dir=\"datasets/ReceiptCOOPData_v0.1_labels_2\"\n",
    "\n",
    "for file in tqdm(txt_files):\n",
    "#     file = mat_files[1]\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    name = file.stem\n",
    "    image_name = name + \".jpg\"\n",
    "    \n",
    "    image_file =  Path(image_folder) / image_name\n",
    "    \n",
    "    if not image_file.is_file():\n",
    "        print(\"File not found\")\n",
    "        continue\n",
    "    \n",
    "    image_size = cv2.imread(str(image_file)).shape[:2]\n",
    "    \n",
    "#     try:\n",
    "    json = txt_to_json_conversion(lines, str(Path(output_image_dir) / image_name), image_size)\n",
    "#     except:\n",
    "#         print(\"Error conversion\")\n",
    "    \n",
    "    nu.write_json(Path(output_dir) / (name + \".json\"), json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.zip(output_dir, \"receiptCoop_label2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3183', '162', '3423', '216', '3365', '470', '3125', '416', 'rn']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0].strip().lower().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rn'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join(lines[0].split(\",\")[8:]).replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(str(file_path.with_suffix('.txt')), 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
